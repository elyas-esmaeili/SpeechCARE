{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLBspE6Zhdfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d975176b-4172-45c5-8329-1bc15dc71fea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d66we_rzhhdS"
      },
      "outputs": [],
      "source": [
        "!pip install spafe\n",
        "!pip install praat-parselmouth\n",
        "!pip install textstat\n",
        "!pip install pocketsphinx\n",
        "!pip install ctranslate2==4.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbIAgZSL8udN"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/m-bain/whisperx.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDwXdaDxhtiZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "os.chdir(\"/content/gdrive/MyDrive/speech_analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBOTjrL3jzDO"
      },
      "outputs": [],
      "source": [
        "from process_file import process_file, process_file_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lOrToLirpaO"
      },
      "outputs": [],
      "source": [
        "import whisperx\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "vad_model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
        "                              model='silero_vad',\n",
        "                              force_reload=True)\n",
        "\n",
        "device = \"cuda\"\n",
        "batch_size = 8 # reduce if low on GPU mem\n",
        "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
        "\n",
        "# 1. Transcribe with original whisper (batched)\n",
        "transcription_model = whisperx.load_model(\"large-v3\", device, compute_type=compute_type)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_group_names(output_file):\n",
        "    names = [\"Pausing behavior\", \"Speech behavior\", \"Frequency Parameters\", \"Spectral Domain\", \"Voice Quality\",\n",
        "             \"Loudness and Intensity\", \"Complexity\", \"Info\"]\n",
        "\n",
        "    ranges = [(0, 11), (11, 137),(137, 377), (377, 6331), (6331, 6475), (6475, 6715), (6715, 6859), (6859, 6861)]\n",
        "\n",
        "    group_names = [\"\"] * 6861\n",
        "    for i, r in enumerate(ranges):\n",
        "        for j in range(r[0], r[1]):\n",
        "            group_names[j] = names[i]\n",
        "    train_df = pd.read_csv(output_file)\n",
        "\n",
        "    column_names = zip(group_names, train_df.columns)\n",
        "    train_df.columns = pd.MultiIndex.from_tuples(column_names)\n",
        "\n",
        "    train_df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "uqggRdNSX-YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCKJFmUwL7aK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import csv\n",
        "\n",
        "\n",
        "def calculate_all_features(input_dir, output_file, label):\n",
        "    previously_calculated = {}\n",
        "    if os.path.exists(output_file):\n",
        "        features_pd = pd.read_csv(output_file)\n",
        "        previously_calculated = set(features_pd[\"filename\"].tolist())\n",
        "\n",
        "\n",
        "    csvfile = open(output_file, \"a+\")\n",
        "    writer = None\n",
        "    write_header = True\n",
        "    if len(previously_calculated) > 0:\n",
        "        write_header = False\n",
        "        df = pd.read_csv(output_file)\n",
        "        fieldnames = list(df.columns)\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    progress_bar = tqdm(range(len(os.listdir(input_dir))), position=0, leave=True)\n",
        "    for file in os.listdir(input_dir):\n",
        "        if file in previously_calculated:\n",
        "            continue\n",
        "        if file.endswith('.wav'):\n",
        "                file_path = os.path.join(input_dir, file)\n",
        "                try:\n",
        "                    acoustic_features = process_file(file_path)\n",
        "                    features = process_file_model(file_path, vad_model, utils, transcription_model)\n",
        "                    features.update(acoustic_features)\n",
        "                    # features = {}\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "                    print(file)\n",
        "                    features = {}\n",
        "                features['filename'] = file\n",
        "                features['label'] = label\n",
        "                if write_header:\n",
        "                    writer = csv.DictWriter(csvfile, fieldnames=features.keys())\n",
        "                    writer.writeheader()\n",
        "                    write_header = False\n",
        "                writer.writerows([features])\n",
        "\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    csvfile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXg7ipLFOkKi"
      },
      "outputs": [],
      "source": [
        "directory_path_ad = \"/content/gdrive/MyDrive/Data/2021/Audio-denoise_new/test_data_2021/AD-test-denoise\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1FhNw5pwp8I",
        "outputId": "fc4e575d-e432-4125-f86d-ba6f86277e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_TRgtKHOqkk"
      },
      "outputs": [],
      "source": [
        "output_file = \"out.csv\"\n",
        "calculate_all_features(directory_path_ad, output_file, 1)\n",
        "add_group_names(output_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}